#+TITLE: Optimization of the Auto-Tuning of HPC Application Computing Kernels
#+LANGUAGE: en
#+Author:
#+TAGS: noexport(n) deprecated(d)
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport

#+LaTeX_CLASS: memoir
#+LaTeX_CLASS_OPTIONS: [12pt, a4paper]
#+OPTIONS: H:5 title:nil author:nil email:nil creator:nil timestamp:nil skip:nil toc:nil ^:nil
#+BABEL: :session *R* :cache yes :results output graphics :exports both :tangle yes 

#+LATEX_HEADER:\usepackage[french,english]{babel}
#+LATEX_HEADER:\usepackage [vscale=0.76,includehead]{geometry}                % See geometry.pdf to learn the layout options. There are lots.
# #+LATEX_HEADER:\geometry{a4paper}                   % ... or a4paper or a5paper or ... 
# #+LATEX_HEADER:\geometry{landscape}                % Activate for for rotated page geometry
# #+LATEX_HEADER:\OnehalfSpacing
# #+LATEX_HEADER: \setSingleSpace{1.05}
# #+LATEX_HEADER:\usepackage[parfill]{parskip}    % Activate to begin paragraphs with an empty line rather than an indent
#+LATEX_HEADER:\usepackage{amsmath}
#+LATEX_HEADER:\usepackage{fullpage}
#+LATEX_HEADER:\usepackage{mathptmx} % font = times
#+LATEX_HEADER:\usepackage{helvet} % font sf = helvetica
#+LATEX_HEADER:\usepackage[latin1]{inputenc}
#+LATEX_HEADER:\usepackage{relsize}
#+LATEX_HEADER:\usepackage{listings}

#+BEGIN_LaTeX
%Style des tÃªtes de section, headings, chapitre
\headstyles{komalike}
\nouppercaseheads
\chapterstyle{dash}
\makeevenhead{headings}{\sffamily\thepage}{}{\sffamily\leftmark} 
\makeoddhead{headings}{\sffamily\rightmark}{}{\sffamily\thepage}
\makeoddfoot{plain}{}{}{} % Pages chapitre. 
\makeheadrule{headings}{\textwidth}{\normalrulethickness}
%\renewcommand{\leftmark}{\thechapter ---}
\renewcommand{\chaptername}{\relax}
\renewcommand{\chaptitlefont}{ \sffamily\bfseries \LARGE}
\renewcommand{\chapnumfont}{ \sffamily\bfseries \LARGE}
\setsecnumdepth{subsection}


% Title page formatting -- do not change!
\pretitle{\HUGE\sffamily \bfseries\begin{center}} 
\posttitle{\end{center}}
\preauthor{\LARGE  \sffamily \bfseries\begin{center}}
\postauthor{\par\end{center}}

\newcommand{\jury}[1]{% 
\gdef\juryB{#1}} 
\newcommand{\juryB}{} 
\newcommand{\session}[1]{% 
\gdef\sessionB{#1}} 
\newcommand{\sessionB}{} 
\newcommand{\option}[1]{% 
\gdef\optionB{#1}} 
\newcommand{\optionB}{} 

\renewcommand{\maketitlehookd}{% 
\vfill{}  \large\par\noindent  
\begin{center}\juryB \bigskip\sessionB\end{center}
\vspace{-1.5cm}}
\renewcommand{\maketitlehooka}{% 
\vspace{-1.5cm}\noindent\includegraphics[height=14ex]{logoINP.png}\hfill\raisebox{2ex}{\includegraphics[height=7ex]{logoUJF.jpg}}\\
\bigskip
\begin{center} \large
Master of Science in Informatics at Grenoble \\
Master Math\'ematiques Informatique - sp\'ecialit\'e Informatique \\ 
option \optionB  \end{center}\vfill}
% End of title page formatting

\option{$<$option-name$>$}
%\title{ Project Title }%\\\vspace{-1ex}\rule{10ex}{0.5pt} \\sub-title} 
\author{Author Name}
\date{ $<$Defense Date$>$} % Delete this line to display the current date
\jury{
Research project performed at $<$lab-name$>$ \\\medskip
Under the supervision of:\\
$<$supervisor's first-name and last-name, supervisor's institution$>$\\\medskip
Defended before a jury composed of:\\
$[$Prof/Dr/Mrs/Mr$]$ $<$first-name last-name$>$\\
$[$Prof/Dr/Mrs/Mr$]$ $<$first-name last-name$>$\\
$[$Prof/Dr/Mrs/Mr$]$ $<$first-name last-name$>$\\
$[$Prof/Dr/Mrs/Mr$]$ $<$first-name last-name$>$\\
}
\session{$[$June/September$]$\hfill year}
#+END_LaTeX

#+BEGIN_abstract
  Blablabla
  \newpage
#+END_abstract

* Plan                                                             :noexport:
** Introduction
   - In HPC code optimization crucial to exploit hardware.
     Cannot wait for the next generation to bring speedup because it
     does not (Frequency not higher but more cores and henanced ISA). 
   - HPC plaforms \ne hardware \to code optimizations not portable.
     Porting application to another platform is time consumming and
     can be very tricky. Automatize the porting using tools \to
     autotuner.

   - BOAST framework ruby generating portable code in C, Fortran,
     OpenCL. DSL
** Problem analysis
   - Huge search space \to need to explore only part of it \to
     optimization problem.
   - Interactions between parameters
   - Non-smooth and empirical objective function
   - Combination of discrete and continuous parameters
     
** State of the art
   # - Atlas \to small search space or if we know where to search \to
   #   exhaustive search 
   # - Local search like gradiant search \to to know where to start
   #   Can be stuck at local minimum and be from the global optimum
   # - Random algorithms random search, genetic algorithm. 
   #   Efficient on complex problem with no geometry.
   #   Can escape from local optimum
   # - Mix of local and global search \to Generalized pattern search
   # - Using modelization get get knowledge about the search space and
   #   to predict behavior
   #   - Learning machine \to categorisation of similar problem to use
   #     same strategy, training overhead
   #   - Regression \to possible to use property of the function, such as
   #     derivative, convexity,etc...
*** Using information about the problem - Objective function
    - Derivative methods \to local strategy
      - If non convex \to multiple local minimum \to need to know where to
        start or randomized strategy e.g. simulated annealing
      - If derivation not possible (empirical function) estimate with regression
*** Using information about the problem - Other kind of knowledge   
    Problem too complex
    Heuristic based: genetic algorithm, random search, pattern search
    Also machine learning \to identifying category of problem and
    strategy that work well
*** Our goal
    - Complex methods used but no explanation on why they work
    - Try a simple approach and try to understand it deeply
    - Analytics methods & experiments design
    - Study of the search space on simple example

** Methods and material
  - Reproducible work
    - Lab book on github  
    - Literate programming 
  - Result validation against bruteforce
  - Comparison with random, gradiant search, and genetic algorithm
** Contribution
*** Case study
    # Maybe this should go in experiments
****  Laplacian
      - Optimizations explanation
        - Vectorization \to vector length
        - Synthetize loading \to load overlap
        - Tilling \to y component number
        - Number of threads \to elements number
        - Size of temporary results \to temporary size
          Reducing pressure on registers? If high usage of registers?
          If not high usage of registers overhead of casting?
        - Size of a work group \to threads number
        - Shape of work group \to lws y
**** Matrix product?
      - Optimizations explanation
*** Why linear regression is not suited
    - Tracks general tendency of the impact of factors
    - Heteroscedasticity
    - Non uniform noise
*** Use of quantile regression
    - Ways of computing quantile regression
    - 5th and 95th percentile \to good estimation for extreme values
    - But optimist R-squared
*** Model choice and refinement
    - Hypothesis based on the kernel
    - Iterative refinement
    - Determines the quality of the prediction
*** Importance of the search space expression
    - Easier modelization
    - Better capture of the search space features
*** Using less point as possible
    - Design of experiment
    - Copying with constraints
** Experiments
   - Bench min of 4 runs \to warm up effect
*** Laplacian
**** Search space characteristics
     - Qualitative observation in term of speed up
**** Comparison with random and genetic algo
** Conclusion

* Introduction
* Problem analysis
* State of the art
* Methods
* Contribution
** Case study
   # Not sure it is necessary:
   # #+BEGIN_LaTeX
   # \lstset{language=C}
   # \begin{lstlisting}
   #   void math(const int32_t width, const int32_t height, const uint8_t * psrc, uint8_t * pdst){
   #       int32_t i;
   #       int32_t j;
   #       int32_t c;
   #       int32_t tmp;
   #       int32_t w;
   #       w = (width) * (3);
   #       for (j = 1; j <= height - (2); j += 1) {
   #           for (i = 1; i <= width - (2); i += 1) {
   #               for (c = 0; c <= 2; c += 1) {
   #                   tmp =  - (psrc[c + (3) * (i - (1) + (width) * (j - (1)))]) 
   #                          - (psrc[c + (3) * (i + (width) * (j - (1)))]) 
   #                          - (psrc[c + (3) * (i + 1 + (width) * (j - (1)))]) 
   #                          - (psrc[c + (3) * (i - (1) + (width) * (j))]) 
   #                          + (psrc[c + (3) * (i + (width) * (j))]) * (9) 
   #                          - (psrc[c + (3) * (i + 1 + (width) * (j))]) 
   #                          - (psrc[c + (3) * (i - (1) + (width) * (j + 1))]) 
   #                          - (psrc[c + (3) * (i + (width) * (j + 1))]) 
   #                          - (psrc[c + (3) * (i + 1 + (width) * (j + 1))]);
   #                   pdst[c + (3) * (i + (width) * (j))] = (tmp < 0 ? 0 : (tmp > 255 ? 255 : tmp));
   #               }
   #           }
   #       }
   #   }
   # \end{lstlisting}
   # #+END_LaTeX

   In order to elaborate our approach, we took a very simple example
   which is a kernel that computes the Laplacian of an image. There
   are multiple optimization that can be done to enhance the
   performance of this kernel. 

   The first optimization we can use is the vectorization, this allows
   to take advantage of hardware capable of executing one instruction
   on multiple data at a time and instead of computing one data, so
   multiple data are computed for the same cost. Thus we can specify
   the length of the vector and we must find what is the correct
   length of the vector. 

   To perform vectorization we need to load more data and some data
   overlap with each other, to reduce the number of load we can
   synthetize those data from other, this is the second optimization
   we can have. 

   Another optimization to henance the performs of the kernel can be
   to use smaller type for intermediary results, reducing the pressure
   on the registers.

   We also can determine the number of threads use to performs the
   computation. More threads can lead to better parallelism but also
   more threads overhead. We do this by specifying the number of
   component a thread will work on. We need know what is the correct
   size of the job for a thread.
   
   After specifying the quantity of work per thread we can specify how
   this work is organized by specifying the tilling. It gives how the
   components are distributed in the y axis.

   There are also two parameters that are important for any
   kernel. First we have the number of threads in work group and then
   the organization of the threads in the work group. These parameters
   defines the work distribution at coarse grain and have an impact on
   the threads scheduling, data sharing. This leads to better usage of
   the resources and it worth to tune it carefully.  
* Experiments
* Conclusion

* Emacs Setup 							   :noexport:
  This document has local variables in its postembule, which should
  allow Org-mode to work seamlessly without any setup. If you're
  uncomfortable using such variables, you can safely ignore them at
  startup. Exporting may require that you copy them in your .emacs.

# Local Variables:
# eval:    (require 'org-install)
# eval:    (org-babel-do-load-languages 'org-babel-load-languages '( (sh . t) (R . t) (perl . t) (ditaa . t) ))
# eval:    (setq org-confirm-babel-evaluate nil)
# eval:    (unless (boundp 'org-latex-classes) (setq org-latex-classes nil))
# eval:    (add-to-list 'org-latex-classes '("memoir" "\\documentclass[smallextended]{memoir} \n \[NO-DEFAULT-PACKAGES]\n \[EXTRA]\n  \\usepackage{graphicx}\n  \\usepackage{hyperref}"  ("\\section{%s}" . "\\section*{%s}") ("\\subsection{%s}" . "\\subsection*{%s}")                       ("\\subsubsection{%s}" . "\\subsubsection*{%s}")                       ("\\paragraph{%s}" . "\\paragraph*{%s}")                       ("\\subparagraph{%s}" . "\\subparagraph*{%s}")))
# eval:    (add-to-list 'org-latex-classes '("acm-proc-article-sp" "\\documentclass{acm_proc_article-sp}\n \[NO-DEFAULT-PACKAGES]\n \[EXTRA]\n"  ("\\section{%s}" . "\\section*{%s}") ("\\subsection{%s}" . "\\subsection*{%s}")                       ("\\subsubsection{%s}" . "\\subsubsection*{%s}")                       ("\\paragraph{%s}" . "\\paragraph*{%s}")                       ("\\subparagraph{%s}" . "\\subparagraph*{%s}")))
# eval:    (setq org-alphabetical-lists t)
# eval:    (setq org-src-fontify-natively t)
# eval:   (setq org-export-babel-evaluate nil)
# eval:   (setq ispell-local-dictionary "english")
# eval:   (eval (flyspell-mode t))
# eval:    (setq org-latex-listings 'minted)
# eval:    (setq org-latex-minted-options '(("bgcolor" "white") ("style" "tango") ("numbers" "left") ("numbersep" "5pt")))
# End:
